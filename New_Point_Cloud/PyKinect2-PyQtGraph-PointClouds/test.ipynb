{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pykinect2 import PyKinectRuntime\n",
    "from pykinect2.PyKinectV2 import FrameSourceTypes_Color\n",
    "from PointCloud import Cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('..\\\\..\\\\CV Model\\\\')\n",
    "# from finetune import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO class labels for torchvision models\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # model = create_model(3)  # Number of classes\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using {device}\")\n",
    "    \n",
    "    # model_path = '..\\\\..\\\\CV Model\\\\chkpt\\\\model.pth'\n",
    "    # model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    # model = torch.load(\"..\\\\..\\\\CV Model\\\\chkpt\\\\model.pth\")\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.to(device) \n",
    "    model.eval()\n",
    "    return model, device\n",
    "\n",
    "\n",
    "def process_frame(frame, model, device):\n",
    "    # Resize frame to make processing more efficient\n",
    "    # resized_frame = cv2.resize(frame, (800, 800))\n",
    "\n",
    "    # Transform the frame to tensor and scale it\n",
    "    frame_tensor = F.to_tensor(frame)\n",
    "    frame_tensor = frame_tensor.to(torch.float32).to(device)\n",
    "\n",
    "    # Correctly format the tensor as a list of 3D tensors [C, H, W]\n",
    "    frame_tensor = frame_tensor.unsqueeze(0)  # Add a batch dimension if it's not already there\n",
    "\n",
    "    # Ensure the tensor is passed as a list of images \n",
    "    frame_tensor_list = [frame_tensor.squeeze(0)]  # This changes it from [1, 3, H, W] to [3, H, W] and wraps in a list\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(frame_tensor_list)[0] \n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def display_predictions(frame, predictions):\n",
    "    # # Extract data from predictions\n",
    "    # labels = predictions['labels']\n",
    "    # boxes = predictions['boxes']\n",
    "    # masks = predictions['masks']  # If using Mask R-CNN\n",
    "\n",
    "    # # Draw boxes and labels on the frame here, or use utility functions from torchvision\n",
    "    # frame_with_boxes = frame  # Placeholder for actual drawing function\n",
    "\n",
    "\n",
    "    # Resize frame to the original display size\n",
    "    # display_frame = cv2.resize(frame, (1920, 1080))\n",
    "    \n",
    "    #########\n",
    "    # labels = predictions['labels']\n",
    "    # boxes = predictions['boxes']\n",
    "    # scores = predictions['scores']\n",
    "\n",
    "    # for box, label, score in zip(boxes, labels, scores):\n",
    "    #     if score > 0.85:  # Display only detections with confidence > 0.85\n",
    "    #         cv2.rectangle(frame, \n",
    "    #                       (int(box[0]), int(box[1])), \n",
    "    #                       (int(box[2]), int(box[3])), \n",
    "    #                       (0, 255, 0), 2)  # Draw rectangle\n",
    "    #         cv2.putText(frame, \n",
    "    #                     f'{label} {score:.2f}', \n",
    "    #                     (int(box[0]), int(box[1] - 10)), \n",
    "    #                     cv2.FONT_HERSHEY_SIMPLEX, \n",
    "    #                     0.5, (0, 255, 0), 2)  # Display label and score\n",
    "\n",
    "    # return frame\n",
    "\n",
    "    labels = predictions['labels']\n",
    "    boxes = predictions['boxes']\n",
    "    scores = predictions['scores']\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > 0.85:  # Display only detections with confidence > 0.5\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            label_name = COCO_INSTANCE_CATEGORY_NAMES[label.item()]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw rectangle\n",
    "            cv2.putText(frame, f'{label_name}: {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)  # Display label and score\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_capture(kinect, model, device):\n",
    "    print(\"Starting color frame capture. Press 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        if kinect.has_new_color_frame():\n",
    "            color_frame = kinect.get_last_color_frame()\n",
    "            color_image = color_frame.reshape((kinect.color_frame_desc.Height,\n",
    "                                               kinect.color_frame_desc.Width, 4)).astype(np.uint8)\n",
    "            \n",
    "            rgb_image = cv2.cvtColor(color_image, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "            # Process frame through model\n",
    "            predictions = process_frame(rgb_image, model, device)\n",
    "            rgb_image_with_preds = display_predictions(rgb_image, predictions)\n",
    "\n",
    "            cv2.imshow('Kinect RGB Stream with CNN Predictions', rgb_image_with_preds)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            # print(\"Waiting for new frame...\")\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_cloud_visualization():\n",
    "    pcl = Cloud(dynamic=True, simultaneously=True, depth=True, color=True, body=False, skeleton=False, color_overlay=False)\n",
    "    # pcl.visualize()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize the Kinect with color and depth frame support\n",
    "    kinect = PyKinectRuntime.PyKinectRuntime(FrameSourceTypes_Color)\n",
    "    model, device = load_model()\n",
    "\n",
    "    # Start the RGB capture thread\n",
    "    rgb_thread = threading.Thread(target=rgb_capture, args=(kinect, model, device))\n",
    "    rgb_thread.start()\n",
    "\n",
    "    # Start the point cloud visualization in the main thread\n",
    "    point_cloud_visualization()\n",
    "\n",
    "    # Wait for the RGB thread to finish\n",
    "    rgb_thread.join()\n",
    "\n",
    "    # Cleanup\n",
    "    kinect.close()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# print(torch.__version__)\n",
    "# print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
