{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pykinect2 import PyKinectRuntime\n",
    "from pykinect2.PyKinectV2 import FrameSourceTypes_Color\n",
    "from PointCloud import Cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..\\\\..\\\\CV Model\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finetune import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO class labels for torchvision models\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes):\n",
    "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    \n",
    "    hidden_layer = 256\n",
    "    \n",
    "    model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # model = create_model(3)  # Number of classes\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using {device}\")\n",
    "    \n",
    "    # model_path = '..\\\\..\\\\CV Model\\\\chkpt\\\\model.pth'\n",
    "    # model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    state_dict_path = \"..\\\\..\\\\CV Model\\\\final_model.pth\"\n",
    "\n",
    "\n",
    "\n",
    "    model = create_model(2)\n",
    "    model.load_state_dict(torch.load(state_dict_path))\n",
    "    # model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.to(device) \n",
    "    model.eval()\n",
    "    return model, device\n",
    "\n",
    "\n",
    "def process_frame(frame, model, device):\n",
    "    # Resize frame to make processing more efficient\n",
    "    # resized_frame = cv2.resize(frame, (800, 800))\n",
    "\n",
    "    # Transform the frame to tensor and scale it\n",
    "    frame_tensor = F.to_tensor(frame)\n",
    "    frame_tensor = frame_tensor.to(torch.float32).to(device)\n",
    "\n",
    "    # Correctly format the tensor as a list of 3D tensors [C, H, W]\n",
    "    frame_tensor = frame_tensor.unsqueeze(0)  # Add a batch dimension if it's not already there\n",
    "\n",
    "    # Ensure the tensor is passed as a list of images \n",
    "    frame_tensor_list = [frame_tensor.squeeze(0)]  # This changes it from [1, 3, H, W] to [3, H, W] and wraps in a list\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(frame_tensor_list)[0] \n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def display_predictions(frame, predictions):\n",
    "    labels = predictions['labels']\n",
    "    boxes = predictions['boxes']\n",
    "    scores = predictions['scores']\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        label_name = COCO_INSTANCE_CATEGORY_NAMES[label.item()]\n",
    "        if score > 0.1:  # Check if the label is \"remote\" and confidence > 0.85\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            label_name = COCO_INSTANCE_CATEGORY_NAMES[label.item()]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw rectangle\n",
    "            cv2.putText(frame, f'{label_name}: {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)  # Display label and score\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_capture(kinect, model, device):\n",
    "    print(\"Starting color frame capture. Press 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        if kinect.has_new_color_frame():\n",
    "            color_frame = kinect.get_last_color_frame()\n",
    "            color_image = color_frame.reshape((kinect.color_frame_desc.Height,\n",
    "                                               kinect.color_frame_desc.Width, 4)).astype(np.uint8)\n",
    "            \n",
    "            rgb_image = cv2.cvtColor(color_image, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "            # Process frame through model\n",
    "            predictions = process_frame(rgb_image, model, device)\n",
    "            rgb_image_with_preds = display_predictions(rgb_image, predictions)\n",
    "\n",
    "            cv2.imshow('Kinect RGB Stream with CNN Predictions', rgb_image_with_preds)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            # print(\"Waiting for new frame...\")\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_cloud_visualization():\n",
    "    # pcl = Cloud(dynamic=True, simultaneously=True, depth=True, color=True, body=False, skeleton=False, color_overlay=False)\n",
    "    # pcl.visualize()\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Varadh\\Desktop\\NEU\\CS5335-Robotic-Science-and-Systems\\Project\\CS5335-4610-Project\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Varadh\\Desktop\\NEU\\CS5335-Robotic-Science-and-Systems\\Project\\CS5335-4610-Project\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting color frame capture. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize the Kinect with color and depth frame support\n",
    "    kinect = PyKinectRuntime.PyKinectRuntime(FrameSourceTypes_Color)\n",
    "    model, device = load_model()\n",
    "\n",
    "    # Start the RGB capture thread\n",
    "    rgb_thread = threading.Thread(target=rgb_capture, args=(kinect, model, device))\n",
    "    rgb_thread.start()\n",
    "\n",
    "    # Start the point cloud visualization in the main thread\n",
    "    point_cloud_visualization()\n",
    "\n",
    "    # Wait for the RGB thread to finish\n",
    "    rgb_thread.join()\n",
    "\n",
    "    # Cleanup\n",
    "    kinect.close()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
